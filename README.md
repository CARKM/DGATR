# DGATR
NN_cenral.ipynb is for the DGATR-centralized model;

dis_train.ipynb is for the DGATR-distributed model;

cooperation.ipynb is for the DGATR-cooperated model.

6x6 folder stores the parameters of all well-trained agents at different load, you can just load it to the model to compare the performance.

# Training procedure
Off-line.ipynb is for you to conduct an off-line training model. The replay buffer store the experience generated by the Q-routing.

After getting the off-line agent at a low load (e.g. load = 1.0), you can start to conduct the online training with different neural network models. The detials are recorded in the notebook.


